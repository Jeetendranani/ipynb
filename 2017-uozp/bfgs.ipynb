{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum funkcije in algoritem BFGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iščemo mimum funkcije $(\\theta_0-2)^2+(\\theta_1-3)^2-42$. Funkcijo in njen gradient zapišemo tako, da ima kot parametre vektor $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta):\n",
    "    return (theta[0]-2)**2 + (theta[1]-3)**2 - 42\n",
    "\n",
    "def grad(theta):\n",
    "    return np.array([2*(theta[0]-2), 2*(theta[1]-3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-29, array([-4, -6]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.array([0, 0])\n",
    "cost(theta), grad(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za iskanje minimuma uporabimo funkcijo ```fmin_l_bfgs_b``` ki implementira algoritem [Broyden–Fletcher–Goldfarb–Shanno z omejenim spominom](https://en.wikipedia.org/wiki/Limited-memory_BFGS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  3.]),\n",
       " -42.0,\n",
       " {'funcalls': 3,\n",
       "  'grad': array([ 0.,  0.]),\n",
       "  'nit': 2,\n",
       "  'task': b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = np.array([0, 0])\n",
    "res = fmin_l_bfgs_b(cost, theta0, grad)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rezultati se ujemajo s pričakovanji. Naša cenovna funkcija ima minimum v točki [2, 3], vrednost funkcije v tej točki je -17, konvergenca algoritma pa je izjemno hitra, saj je postopek našel minimum s samo tremi klici kriterijske funkcije in njenega gradienta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metoda končnih razlik"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vedno je dobro preveriti, ali smo funkcijo, ki izračuna gradient, implementirali pravilno oziroma ali je analitična rešitev (izračun gradienta). Analitično izračunani in implementirani gradient kriterijske funkcije lahko primerjamo z  gradientom, ki ga izračunamo z metodo končnih razlik. Gradient računamo pri izbrani vrednosti parametrov $\\theta$. Če bi imeli opravka s funkcijo enega samega parametra, bi z metodo končnih razlik odvod ocenili kot $f((\\theta+\\epsilon)-f(\\theta-\\epsilon)/(2\\epsilon)$. Ker pa imamo opravka s kriterijsko funkcijo več parametrov ($\\Theta$ je vektor), njene parcialne odvode izračunamo tako, da vsakič spreminjamo enega izmed parametrov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_approx(f, theta, e=1e-3):\n",
    "    return np.array([(f(theta+eps) - f(theta-eps))/(2*e)\n",
    "                     for eps in np.identity(len(theta)) * e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-4., -6.]), array([-4, -6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_approx(cost, theta0), grad(theta0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dela! Gradienta sta enaka. Seveda bo pri bolj kompleksnih kriterijskih funkcijah ta enakost približna in tudi odvisna od vrednosti premika $\\epsilon$. Opazimo tudi, da je ta v naši implementaciji za vse atribute enak, kar ni ravno optimalno in bi bilo bolje, če bi atributi izraženi na isti merski lestvici, torej če bi bili normirani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearna regresija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritma L-BFGS sedaj uporabimo za linearno regresijo. Za podatke uporabimo zbirko housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 506\n",
      "Attributes: 13\n"
     ]
    }
   ],
   "source": [
    "import Orange\n",
    "data = Orange.data.Table(\"housing\")\n",
    "print(\"Examples: %d\" % len(data))\n",
    "print(\"Attributes: %d\" % len(data.domain.attributes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orange-ov objekt `data` vsebuje opis spremenljivk ter dve tabeli, tabelo atributov $X$ in vektor razredov $y$. Ker bomo tu potrebovali samo ta dva zapisa, in ker sta ta že v zapisu numpy, uvedemo novi spremenljivki, ki kažeta na te objekte. Matriko $X$ razširimo s kolono enic za računanje $\\theta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.X, data.Y\n",
    "X = np.column_stack((np.ones(len(X)), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izpišemo prva dva primera iz učne množice in dimenzije matrike X in vektorja y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   6.32000000e-03,   1.80000000e+01,\n",
       "          2.31000000e+00,   0.00000000e+00,   5.38000000e-01,\n",
       "          6.57500000e+00,   6.52000000e+01,   4.09000000e+00,\n",
       "          1.00000000e+00,   2.96000000e+02,   1.53000000e+01,\n",
       "          3.96900000e+02,   4.98000000e+00],\n",
       "       [  1.00000000e+00,   2.73100000e-02,   0.00000000e+00,\n",
       "          7.07000000e+00,   0.00000000e+00,   4.69000000e-01,\n",
       "          6.42100000e+00,   7.89000000e+01,   4.96710000e+00,\n",
       "          2.00000000e+00,   2.42000000e+02,   1.78000000e+01,\n",
       "          3.96900000e+02,   9.14000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((506, 14), (506,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za linearno regresijo zapišemo cenovno funkcijo in funkcijo, ki vrača gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(theta, X, y):\n",
    "    return (1 / (2 * len(data))) * np.sum((X.dot(theta) - y)**2)\n",
    "\n",
    "def grad(theta, X, y):\n",
    "    return (1 / len(data)) * (X.dot(theta) - y).dot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preverimo izračun gradienta. Kriterijska funkcija J ima za argumente theto, opis primerov in razredni vektor, grad_approx pa kliče funkcijo, za katero računa gradient, samo z theto. Problem rešimo z novo funkcijo s privzetimi argumenti, ki jo uvedemo s konstruktom lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.35213760e+02,   1.72940925e+03,   2.89336210e+03,\n",
       "          4.26879435e+03,   2.25228442e+01,   1.94350160e+02,\n",
       "          2.07986167e+03,   2.47991490e+04,   1.14535166e+03,\n",
       "          3.96326488e+03,   1.53197399e+05,   6.29560114e+03,\n",
       "          1.16701488e+05,   4.70805337e+03]),\n",
       " array([  3.35213760e+02,   1.72940925e+03,   2.89336210e+03,\n",
       "          4.26879435e+03,   2.25228442e+01,   1.94350160e+02,\n",
       "          2.07986167e+03,   2.47991490e+04,   1.14535166e+03,\n",
       "          3.96326488e+03,   1.53197399e+05,   6.29560114e+03,\n",
       "          1.16701488e+05,   4.70805337e+03]),\n",
       " 3.9360624981554793e-08)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.rand(X.shape[1])\n",
    "g = grad(theta, X, y)\n",
    "gp = grad_approx(lambda t, X=X, y=y: J(t, X, y), theta)\n",
    "g, gp, np.sum(np.abs(g - gp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = np.zeros(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.57967712e+01,  -1.08093081e-01,   4.66882362e-02,\n",
       "          2.13456086e-02,   2.64074512e+00,  -1.77178974e+01,\n",
       "          3.85310804e+00,   8.50473295e-04,  -1.47132044e+00,\n",
       "          3.03650373e-01,  -1.22674708e-02,  -9.38811529e-01,\n",
       "          9.42404540e-03,  -5.22704439e-01]),\n",
       " 10.948023361492092,\n",
       " {'funcalls': 2557,\n",
       "  'grad': array([-0.00088407, -0.00499033,  0.00982557,  0.00709474, -0.00335345,\n",
       "         -0.00076431,  0.0021781 ,  0.03443767,  0.00132969,  0.00575186,\n",
       "          0.30465147,  0.02588604,  0.21551422,  0.0034818 ]),\n",
       "  'nit': 2212,\n",
       "  'task': b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH',\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = fmin_l_bfgs_b(J, x0=theta0, args=(X, y), fprime=grad)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tudi tu je, glede na velikost podatkov, konvergenca hitra. Ne vemo sicer, kako dober je model. V tej točki bi morali oceniti napovedno točno modela (prečno preverjanje) ter pregledati, ali je model skladen z domenskim znanjem oziroma ali so uteži atributov ($\\Theta$) smiselne. Za končno uporabo in interpretacijo bi morali podatke ustrezno normalizirati (vsaki koloni odštejemo povprečne vrednosti in delimo s standardno deviacijo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lahko pa vseeno izračunamo, kako dober je naš model na učnih podatkih. Parametri linearne regresije so shranjeni kot prvi element terke, ki ga vrne ```fmin_l_bfgs_b```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6793211818579179"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = res[0]\n",
    "y_hat = X.dot(theta)\n",
    "rmse = np.sqrt(np.sum((y - y_hat)**2)/len(y))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE, kot številka, nam ne pove prav dosti. Poznati moramo domeno. Podatki, ki jih uporabljamo, govorijo o cenah hiš, napaka 4.6 pa v tisočih dolarjih na prvi pogled ne izgleda ravno velika. A kakšna bi bila napaka, če bi namesto našega linearnega napovednega modela uporabili kar povprečno vrednost spremenljivke y iz učne množice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.1880115452782025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean = np.sum(y) / len(y)\n",
    "np.sqrt(np.sum((y - y_mean)**2)/len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Napaka linearni model na učni množici je torej precej manjša. V statistiki poznamo zanimivo mero, ki ji pravimo [delež razložene variance](https://en.wikipedia.org/wiki/Coefficient_of_determination) oziroma koeficient določenosti. Varianca je mera statistične razpršenosti naključne spremenljivke, oziroma povprečno kvadratno odstopanje od povprečne vrednosti naključne spremenljivke. Pravimo, da dober model za vse primere to odstopanje dobro pojasni oziroma ga napove, torej za vsak posamezen primere dobro napove, kako njegova razredna vrednost odstopa od njenega povprečja. Delež razložene variance zato to odstopanje modela zmeri in ga normira z varianco okoli povprečne vrednosti ter dobljeno vrednost odšteje od 1. Delež razložene ima vrednost 1.0 (100%) za modele, ki napovedujejo brez napak, ter 0.0 (0%) za modele, katerih napoved je kar povprečna vrednost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74062826529815839"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tot = np.sum((y-y_mean)**2) # total sum of squares\n",
    "ss_res = np.sum((y-y_hat)**2) # residual sum of squares\n",
    "r2 = 1 - ss_res / ss_tot # coefficient of determination\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naš model razloži 74% variance, kar je soliden rezultat. Popoln model bi razložil 100% variance, slab model, torej tak, ki bi napovedoval kar s povprečnimi vrednostmi, pa na razloži ničesar in je njegov $R^2=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preiskus delovanja na sintetični podatkih"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu preverimo delovanje linearne regresije, kot smo jo implementirali, na sintetičnih podatkih. In sicer bomo te generirali za funkcijo $y=3x+42$, kjer pa bomo poleg kolone z vrednostjo $x$ dodali tudi kolono z naključnimi števili. Lahko bi takih, naključnih kolon dodali več, a bomo to prepustili bralcu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 10\n",
    "xs = np.arange(0, m, 1)\n",
    "y = (3 * xs + 42)  + np.random.normal(0, 3, m)\n",
    "X = np.array([[i, np.random.rand()*m] for i in xs])\n",
    "X = np.column_stack((np.ones(len(X)), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41.23181417,   2.77063114,   0.37209097]),\n",
       " 0.057351124442747578,\n",
       " {'funcalls': 13,\n",
       "  'grad': array([ -3.36323214e-09,  -1.73500777e-08,  -2.30144741e-08]),\n",
       "  'nit': 11,\n",
       "  'task': b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = np.zeros(X.shape[1])\n",
    "res = fmin_l_bfgs_b(J, x0=theta0, args=(X, y), fprime=grad)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQkAmRpkQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e0de710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[:, 1], y, \"o\")\n",
    "p = np.array([[1, 0, 0], [1, 10, 0]])\n",
    "plt.plot(p[:, 1], p.dot(res[0]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dela. Tudi parametre modela kar dobro zadane, glede na to, da je primerov samo 10. Z zvišanjem števila primerov dobimo še boljo oceno parametrov. Poskusi!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
